
该网络的亮点在于：

（1）首次利用 GPU 进行网络加速训练。

（2）使用了 ReLU 激活函数，而不是传统的 Sigmoid 激活函数以及 Tanh 激活函数。

（3）使用了 LRN 局部响应归一化。

（4）在全连接层的前两层中使用了 Dropout 随机失活神经元操作，以减少过拟合。

[AlexNet网络（开山之作）](http://t.zoukankan.com/liang1013-p-14579214.html)

[AlexNet网络模型讲解搭建以及训练](https://www.php.cn/faq/479124.html)

[手撕 CNN 经典网络之 AlexNet（理论篇）](https://zhuanlan.zhihu.com/p/467017218)

![AlexNet_archtechture](https://img-blog.csdnimg.cn/d430447fb35a46848890fc6b5cf04032.png)
![AlexNet_archtechture](https://img.php.cn/upload/article/000/000/062/3fe11b59a92e4a4d66f88618ed394f0b-2.png)
![AlexNet_archtechture](https://img.php.cn/upload/article/000/000/062/4a7e44b53651991bace6042ce48ef22e-3.png)

