{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c86a811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,sys,os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3d4dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download training data from open datasets.\n",
    "# training_data = datasets.CIFAR10(\n",
    "#     root=\"~/data/CIFAR10/\",\n",
    "#     train=True,\n",
    "#     download=True,\n",
    "#     transform=ToTensor(),\n",
    "# )\n",
    "\n",
    "# # Download test data from open datasets.\n",
    "# test_data = datasets.CIFAR10(\n",
    "#     root=\"~/data/CIFAR10/\",\n",
    "#     train=False,\n",
    "#     download=True,\n",
    "#     transform=ToTensor(),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c27fb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57bf5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=[1,2], bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(size=5, k=2, alpha=1e-4, beta=0.75),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(size=5, k=2, alpha=1e-4, beta=0.75),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=0, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features= 6400,out_features= 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features= 4096,out_features= 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features= 4096,out_features= 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        y = self.FC(x)\n",
    "        \n",
    "        return y\n",
    "\n",
    "model = AlexNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a6cce1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4), padding=(1, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (FC): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9f5c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transform=transforms.Compose(\n",
    "# #     [transforms.ToTensor(),\n",
    "# #      transforms.Normalize((0.5,0.5,0.5,),(0.5,0.5,0.5))\n",
    "# #     ]\n",
    "# # )\n",
    "\n",
    "# # Download training data from open datasets.\n",
    "# train_set = datasets.CIFAR10(\n",
    "#     root=\"~/data/CIFAR10/\",\n",
    "#     train=True,\n",
    "#     download=True,\n",
    "#     transform=ToTensor() # transform,\n",
    "# )\n",
    "# trainloader=torch.utils.data.DataLoader(\n",
    "# \ttrain_set,\n",
    "# \tbatch_size=36,\n",
    "# \tshuffle=True,\n",
    "# \tnum_workers=0\n",
    "# \t)\n",
    "\n",
    "\n",
    "# # Download test data from open datasets.\n",
    "# test_set = datasets.CIFAR10(\n",
    "#     root=\"~/data/CIFAR10/\",\n",
    "#     train=False,\n",
    "#     download=True,\n",
    "#     transform=ToTensor() # transform,\n",
    "# )\n",
    "# testloader=torch.utils.data.DataLoader(\n",
    "# \ttest_set,\n",
    "# \tbatch_size=10000,\n",
    "# \tshuffle=False,\n",
    "# \tnum_workers=0\n",
    "# \t)\n",
    "\n",
    "# test_data_iter=iter(testloader)\n",
    "# test_image,test_label=test_data_iter.next()\n",
    "# test_num  = len(test_set)\n",
    "\n",
    "# train_steps = len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef099365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # mkdir val && mv ILSVRC2012_img_val.tar val/ && cd val && tar -xvf ILSVRC2012_img_val.tar\n",
    "# # # wget -qO- https://raw.githubusercontent.com/soumith/imagenetloader.torch/master/valprep.sh | bash\n",
    "\n",
    "# transform=transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5,0.5,0.5,),(0.5,0.5,0.5)),\n",
    "# \t transforms.Resize([227, 227])\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Download training data from open datasets.\n",
    "# train_set = datasets.ImageNet(\n",
    "#     root=\"~/data/ImageNet/\",\n",
    "#     split='train',\n",
    "#     # download=True,\n",
    "#     # transform=ToTensor() # transform,\n",
    "# \ttransform=transform,\n",
    "# )\n",
    "# trainloader=torch.utils.data.DataLoader(\n",
    "# \ttrain_set,\n",
    "# \tbatch_size=36,\n",
    "# \tshuffle=True,\n",
    "# \tnum_workers=0\n",
    "# \t)\n",
    "\n",
    "\n",
    "# # # Download test data from open datasets.\n",
    "# test_set = datasets.ImageNet(\n",
    "#     root=\"~/data/ImageNet/\",\n",
    "#     split='val',\n",
    "#     # download=True,\n",
    "#     # transform=ToTensor() # transform,\n",
    "# \ttransform= transform,\n",
    "# )\n",
    "# testloader=torch.utils.data.DataLoader(\n",
    "# \ttest_set,\n",
    "# \tbatch_size=10000,\n",
    "# \tshuffle=True,\n",
    "# \tnum_workers=0\n",
    "# \t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,0.5,0.5,),(0.5,0.5,0.5)),\n",
    "\t transforms.Resize([227, 227])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Download training data from open datasets.\n",
    "train_set = datasets.CIFAR10(\n",
    "    root=\"~/data/CIFAR10/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform, # transform,\n",
    ")\n",
    "trainloader=torch.utils.data.DataLoader(\n",
    "\ttrain_set,\n",
    "\tbatch_size=256,\n",
    "\tshuffle=True,\n",
    "\tnum_workers=0\n",
    "\t)\n",
    "\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_set = datasets.CIFAR10(\n",
    "    root=\"~/data/CIFAR10/\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform, # transform,\n",
    ")\n",
    "testloader=torch.utils.data.DataLoader(\n",
    "\ttest_set,\n",
    "\tbatch_size=256,\n",
    "\tshuffle=True,\n",
    "\tnum_workers=0\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abd44d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data_iter=iter(testloader)\n",
    "# test_image,test_label=test_data_iter.next()\n",
    "test_num  = len(test_set)\n",
    "\n",
    "train_steps = len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "077a2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义一个优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "# optimizer = torch.optim.SGD(model.parameters(),lr=0.001)\n",
    "\n",
    "epochs = 40\n",
    "\n",
    "save_path= './AlexNet.pth'\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "233f2a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch[1/40] loss:1.452: 100%|██████████| 196/196 [01:56<00:00,  1.69it/s]\n",
      "100%|██████████| 40/40 [00:14<00:00,  2.82it/s]\n",
      "[epoch 1] train_loss: 1.868  val_accuracy: 0.446\n",
      "train epoch[2/40] loss:1.219: 100%|██████████| 196/196 [01:55<00:00,  1.70it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.88it/s]\n",
      "[epoch 2] train_loss: 1.329  val_accuracy: 0.560\n",
      "train epoch[3/40] loss:0.779: 100%|██████████| 196/196 [01:56<00:00,  1.68it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.88it/s]\n",
      "[epoch 3] train_loss: 1.111  val_accuracy: 0.624\n",
      "train epoch[4/40] loss:0.988: 100%|██████████| 196/196 [01:55<00:00,  1.69it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.94it/s]\n",
      "[epoch 4] train_loss: 0.977  val_accuracy: 0.654\n",
      "train epoch[5/40] loss:0.776: 100%|██████████| 196/196 [01:55<00:00,  1.70it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.92it/s]\n",
      "[epoch 5] train_loss: 0.866  val_accuracy: 0.691\n",
      "train epoch[6/40] loss:0.785: 100%|██████████| 196/196 [01:54<00:00,  1.71it/s]\n",
      "100%|██████████| 40/40 [00:14<00:00,  2.83it/s]\n",
      "[epoch 6] train_loss: 0.773  val_accuracy: 0.707\n",
      "train epoch[7/40] loss:0.559: 100%|██████████| 196/196 [02:28<00:00,  1.32it/s]\n",
      "100%|██████████| 40/40 [00:17<00:00,  2.27it/s]\n",
      "[epoch 7] train_loss: 0.703  val_accuracy: 0.720\n",
      "train epoch[8/40] loss:0.475: 100%|██████████| 196/196 [02:30<00:00,  1.30it/s]\n",
      "100%|██████████| 40/40 [00:14<00:00,  2.73it/s]\n",
      "[epoch 8] train_loss: 0.625  val_accuracy: 0.731\n",
      "train epoch[9/40] loss:0.420: 100%|██████████| 196/196 [01:58<00:00,  1.65it/s]\n",
      "100%|██████████| 40/40 [00:15<00:00,  2.66it/s]\n",
      "[epoch 9] train_loss: 0.553  val_accuracy: 0.727\n",
      "train epoch[10/40] loss:0.487: 100%|██████████| 196/196 [01:57<00:00,  1.67it/s]\n",
      "100%|██████████| 40/40 [00:14<00:00,  2.72it/s]\n",
      "[epoch 10] train_loss: 0.493  val_accuracy: 0.720\n",
      "train epoch[11/40] loss:0.441: 100%|██████████| 196/196 [01:58<00:00,  1.66it/s]\n",
      "100%|██████████| 40/40 [00:14<00:00,  2.80it/s]\n",
      "[epoch 11] train_loss: 0.439  val_accuracy: 0.730\n",
      "train epoch[12/40] loss:0.360: 100%|██████████| 196/196 [01:57<00:00,  1.67it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.95it/s]\n",
      "[epoch 12] train_loss: 0.394  val_accuracy: 0.728\n",
      "train epoch[13/40] loss:0.363: 100%|██████████| 196/196 [01:57<00:00,  1.67it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.89it/s]\n",
      "[epoch 13] train_loss: 0.356  val_accuracy: 0.741\n",
      "train epoch[14/40] loss:0.420: 100%|██████████| 196/196 [01:57<00:00,  1.67it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.88it/s]\n",
      "[epoch 14] train_loss: 0.310  val_accuracy: 0.738\n",
      "train epoch[15/40] loss:0.345: 100%|██████████| 196/196 [01:57<00:00,  1.67it/s]\n",
      "100%|██████████| 40/40 [00:14<00:00,  2.80it/s]\n",
      "[epoch 15] train_loss: 0.293  val_accuracy: 0.732\n",
      "train epoch[16/40] loss:0.377: 100%|██████████| 196/196 [01:58<00:00,  1.66it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.91it/s]\n",
      "[epoch 16] train_loss: 0.268  val_accuracy: 0.737\n",
      "train epoch[17/40] loss:0.298: 100%|██████████| 196/196 [01:57<00:00,  1.67it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.90it/s]\n",
      "[epoch 17] train_loss: 0.234  val_accuracy: 0.740\n",
      "train epoch[18/40] loss:0.202: 100%|██████████| 196/196 [01:57<00:00,  1.67it/s]\n",
      "100%|██████████| 40/40 [00:14<00:00,  2.84it/s]\n",
      "[epoch 18] train_loss: 0.230  val_accuracy: 0.736\n",
      "train epoch[19/40] loss:0.220: 100%|██████████| 196/196 [01:57<00:00,  1.67it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.94it/s]\n",
      "[epoch 19] train_loss: 0.219  val_accuracy: 0.727\n",
      "train epoch[20/40] loss:0.377: 100%|██████████| 196/196 [01:57<00:00,  1.66it/s]\n",
      "100%|██████████| 40/40 [00:14<00:00,  2.78it/s]\n",
      "[epoch 20] train_loss: 0.210  val_accuracy: 0.736\n",
      "train epoch[21/40] loss:0.335: 100%|██████████| 196/196 [01:57<00:00,  1.66it/s]\n",
      "100%|██████████| 40/40 [00:14<00:00,  2.75it/s]\n",
      "[epoch 21] train_loss: 0.195  val_accuracy: 0.741\n",
      "train epoch[22/40] loss:0.103: 100%|██████████| 196/196 [01:57<00:00,  1.66it/s]\n",
      "100%|██████████| 40/40 [00:14<00:00,  2.80it/s]\n",
      "[epoch 22] train_loss: 0.167  val_accuracy: 0.737\n",
      "train epoch[23/40] loss:0.199: 100%|██████████| 196/196 [01:58<00:00,  1.66it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.87it/s]\n",
      "[epoch 23] train_loss: 0.160  val_accuracy: 0.726\n",
      "train epoch[24/40] loss:0.282: 100%|██████████| 196/196 [01:58<00:00,  1.66it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.86it/s]\n",
      "[epoch 24] train_loss: 0.177  val_accuracy: 0.734\n",
      "train epoch[25/40] loss:0.106: 100%|██████████| 196/196 [01:57<00:00,  1.67it/s]\n",
      "100%|██████████| 40/40 [00:14<00:00,  2.77it/s]\n",
      "[epoch 25] train_loss: 0.151  val_accuracy: 0.722\n",
      "train epoch[26/40] loss:0.106: 100%|██████████| 196/196 [01:57<00:00,  1.66it/s]\n",
      "100%|██████████| 40/40 [00:14<00:00,  2.78it/s]\n",
      "[epoch 26] train_loss: 0.159  val_accuracy: 0.734\n",
      "train epoch[27/40] loss:0.259: 100%|██████████| 196/196 [01:56<00:00,  1.68it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.94it/s]\n",
      "[epoch 27] train_loss: 0.167  val_accuracy: 0.737\n",
      "train epoch[28/40] loss:0.176: 100%|██████████| 196/196 [01:58<00:00,  1.66it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.87it/s]\n",
      "[epoch 28] train_loss: 0.145  val_accuracy: 0.731\n",
      "train epoch[29/40] loss:0.214: 100%|██████████| 196/196 [01:57<00:00,  1.67it/s]\n",
      "100%|██████████| 40/40 [00:14<00:00,  2.84it/s]\n",
      "[epoch 29] train_loss: 0.149  val_accuracy: 0.729\n",
      "train epoch[30/40] loss:0.280: 100%|██████████| 196/196 [01:56<00:00,  1.68it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.93it/s]\n",
      "[epoch 30] train_loss: 0.155  val_accuracy: 0.733\n",
      "train epoch[31/40] loss:0.096: 100%|██████████| 196/196 [01:57<00:00,  1.66it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.94it/s]\n",
      "[epoch 31] train_loss: 0.139  val_accuracy: 0.736\n",
      "train epoch[32/40] loss:0.132: 100%|██████████| 196/196 [01:57<00:00,  1.66it/s]\n",
      "100%|██████████| 40/40 [00:14<00:00,  2.83it/s]\n",
      "[epoch 32] train_loss: 0.134  val_accuracy: 0.735\n",
      "train epoch[33/40] loss:0.028: 100%|██████████| 196/196 [01:57<00:00,  1.67it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.94it/s]\n",
      "[epoch 33] train_loss: 0.131  val_accuracy: 0.740\n",
      "train epoch[34/40] loss:0.163: 100%|██████████| 196/196 [01:57<00:00,  1.67it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.91it/s]\n",
      "[epoch 34] train_loss: 0.135  val_accuracy: 0.727\n",
      "train epoch[35/40] loss:0.105: 100%|██████████| 196/196 [01:58<00:00,  1.65it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.93it/s]\n",
      "[epoch 35] train_loss: 0.142  val_accuracy: 0.724\n",
      "train epoch[36/40] loss:0.041: 100%|██████████| 196/196 [01:58<00:00,  1.66it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.91it/s]\n",
      "[epoch 36] train_loss: 0.137  val_accuracy: 0.739\n",
      "train epoch[37/40] loss:0.093: 100%|██████████| 196/196 [01:57<00:00,  1.67it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.87it/s]\n",
      "[epoch 37] train_loss: 0.114  val_accuracy: 0.741\n",
      "train epoch[38/40] loss:0.060: 100%|██████████| 196/196 [01:57<00:00,  1.67it/s]\n",
      "100%|██████████| 40/40 [00:14<00:00,  2.85it/s]\n",
      "[epoch 38] train_loss: 0.125  val_accuracy: 0.736\n",
      "train epoch[39/40] loss:0.114: 100%|██████████| 196/196 [01:57<00:00,  1.67it/s]\n",
      "100%|██████████| 40/40 [00:14<00:00,  2.86it/s]\n",
      "[epoch 39] train_loss: 0.113  val_accuracy: 0.745\n",
      "train epoch[40/40] loss:0.073: 100%|██████████| 196/196 [01:57<00:00,  1.67it/s]\n",
      "100%|██████████| 40/40 [00:13<00:00,  2.92it/s]\n",
      "[epoch 40] train_loss: 0.126  val_accuracy: 0.733\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "for epoch in range(epochs):\n",
    "        # train\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_bar = tqdm(trainloader, file=sys.stdout)\n",
    "        for step, data in enumerate(train_bar):\n",
    "            images, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images.to(device))\n",
    "            loss = loss_fn(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
    "                                                                     epochs,\n",
    "                                                                     loss)\n",
    "\n",
    "# validate\n",
    "        model.eval()\n",
    "        acc = 0.0  # accumulate accurate number / epoch\n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(testloader, file=sys.stdout) # show progress\n",
    "            for val_data in val_bar:\n",
    "                val_images, val_labels = val_data\n",
    "                outputs = model(val_images.to(device))\n",
    "                predict_y = torch.max(outputs, dim=1)[1]\n",
    "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "\n",
    "        val_accurate = acc / test_num\n",
    "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
    "              (epoch + 1, running_loss / train_steps, val_accurate))\n",
    "\n",
    "        if val_accurate > best_acc:\n",
    "            best_acc = val_accurate\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "\n",
    "print('Finished Training') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "739d44a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7453"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ryan': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e70b0d8493b7f59e214a43b868537ebeafe12cb89daa279090c57b89e62c1c99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
