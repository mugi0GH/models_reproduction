{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fNeXLdf_ekmq"
      },
      "outputs": [],
      "source": [
        "import torch,sys,os\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzq0Y5WX2-NU"
      },
      "source": [
        "# Self reproduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Optional,Callable\n",
        "\n",
        "class GoogLeNet_v1(nn.Module):\n",
        "    def __init__(self,num_classes=1000,init_weights=False):\n",
        "        super(GoogLeNet_v1,self).__init__()\n",
        "\n",
        "        self.Conv = nn.Sequential(\n",
        "            # 使用7x7的卷积核（滑动步长2，padding为3），64通道，输出为112x112x64，卷积后进行ReLU操作\n",
        "            nn.Conv2d(kernel_size=7,stride=2,padding=3,out_channels=64,in_channels=3), \n",
        "            nn.ReLU(),\n",
        "\n",
        "            # 经过3x3的max pooling（步长为2），输出为((112 - 3+1)/2)+1=56，即56x56x64，再进行ReLU操作\n",
        "            nn.MaxPool2d(stride=2,kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.LocalResponseNorm(size=5, k=2, alpha=1e-4, beta=0.75),\n",
        "\n",
        "            # 使用3x3的卷积核（滑动步长为1，padding为1），192通道，输出为56x56x192，卷积后进行ReLU操作\n",
        "\n",
        "            nn.Conv2d(in_channels=64,out_channels=64,kernel_size=1),\n",
        "            nn.LocalResponseNorm(size=5, k=2, alpha=1e-4, beta=0.75),\n",
        "            nn.Conv2d(in_channels=64,out_channels=192,kernel_size=3,stride=1),\n",
        "            nn.LocalResponseNorm(size=5, k=2, alpha=1e-4, beta=0.75),\n",
        "            nn.ReLU(),\n",
        "            # 经过3x3的max pooling（步长为2），输出为((56 - 3+1)/2)+1=28，即28x28x192，再进行ReLU操作\n",
        "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.Inception_3a = Inception(in_channels=64,ch1x1=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x= self.Conv(x)\n",
        "        y\n",
        "        return y\n",
        "\n",
        "\n",
        "class Inception(nn.Module):\n",
        "    def __init__(self,\n",
        "        in_channels: int,\n",
        "        ch1x1: int,\n",
        "        ch3x3red: int,\n",
        "        ch3x3: int,\n",
        "        ch5x5red: int,\n",
        "        ch5x5: int,\n",
        "        pool_proj: int,\n",
        "        conv_block: Optional[Callable[..., nn.Module]] = None,) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk2GUtd324J5"
      },
      "source": [
        "# Pytorch Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na3tP_1Jekmy",
        "outputId": "114d18c2-3381-4d00-f6aa-2c3e1f765e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "from collections import namedtuple\n",
        "from functools import partial\n",
        "from typing import Any, Callable, List, Optional, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "\n",
        "from ..transforms._presets import ImageClassification\n",
        "from ..utils import _log_api_usage_once\n",
        "from ._api import register_model, Weights, WeightsEnum\n",
        "from ._meta import _IMAGENET_CATEGORIES\n",
        "from ._utils import _ovewrite_named_param, handle_legacy_interface\n",
        "\n",
        "\n",
        "__all__ = [\"GoogLeNet\", \"GoogLeNetOutputs\", \"_GoogLeNetOutputs\", \"GoogLeNet_Weights\", \"googlenet\"]\n",
        "\n",
        "\n",
        "GoogLeNetOutputs = namedtuple(\"GoogLeNetOutputs\", [\"logits\", \"aux_logits2\", \"aux_logits1\"])\n",
        "GoogLeNetOutputs.__annotations__ = {\"logits\": Tensor, \"aux_logits2\": Optional[Tensor], \"aux_logits1\": Optional[Tensor]}\n",
        "\n",
        "# Script annotations failed with _GoogleNetOutputs = namedtuple ...\n",
        "# _GoogLeNetOutputs set here for backwards compat\n",
        "_GoogLeNetOutputs = GoogLeNetOutputs\n",
        "\n",
        "\n",
        "class GoogLeNet(nn.Module):\n",
        "    __constants__ = [\"aux_logits\", \"transform_input\"]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes: int = 1000,\n",
        "        aux_logits: bool = True,\n",
        "        transform_input: bool = False,\n",
        "        init_weights: Optional[bool] = None,\n",
        "        blocks: Optional[List[Callable[..., nn.Module]]] = None,\n",
        "        dropout: float = 0.2,\n",
        "        dropout_aux: float = 0.7,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        _log_api_usage_once(self)\n",
        "        if blocks is None:\n",
        "            blocks = [BasicConv2d, Inception, InceptionAux]\n",
        "        if init_weights is None:\n",
        "            warnings.warn(\n",
        "                \"The default weight initialization of GoogleNet will be changed in future releases of \"\n",
        "                \"torchvision. If you wish to keep the old behavior (which leads to long initialization times\"\n",
        "                \" due to scipy/scipy#11299), please set init_weights=True.\",\n",
        "                FutureWarning,\n",
        "            )\n",
        "            init_weights = True\n",
        "        if len(blocks) != 3:\n",
        "            raise ValueError(f\"blocks length should be 3 instead of {len(blocks)}\")\n",
        "        conv_block = blocks[0]\n",
        "        inception_block = blocks[1]\n",
        "        inception_aux_block = blocks[2]\n",
        "\n",
        "        self.aux_logits = aux_logits\n",
        "        self.transform_input = transform_input\n",
        "\n",
        "        self.conv1 = conv_block(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
        "        self.conv2 = conv_block(64, 64, kernel_size=1)\n",
        "        self.conv3 = conv_block(64, 192, kernel_size=3, padding=1)\n",
        "        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception3a = inception_block(192, 64, 96, 128, 16, 32, 32)\n",
        "        self.inception3b = inception_block(256, 128, 128, 192, 32, 96, 64)\n",
        "        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception4a = inception_block(480, 192, 96, 208, 16, 48, 64)\n",
        "        self.inception4b = inception_block(512, 160, 112, 224, 24, 64, 64)\n",
        "        self.inception4c = inception_block(512, 128, 128, 256, 24, 64, 64)\n",
        "        self.inception4d = inception_block(512, 112, 144, 288, 32, 64, 64)\n",
        "        self.inception4e = inception_block(528, 256, 160, 320, 32, 128, 128)\n",
        "        self.maxpool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception5a = inception_block(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5b = inception_block(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "        if aux_logits:\n",
        "            self.aux1 = inception_aux_block(512, num_classes, dropout=dropout_aux)\n",
        "            self.aux2 = inception_aux_block(528, num_classes, dropout=dropout_aux)\n",
        "        else:\n",
        "            self.aux1 = None  # type: ignore[assignment]\n",
        "            self.aux2 = None  # type: ignore[assignment]\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "        if init_weights:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                    torch.nn.init.trunc_normal_(m.weight, mean=0.0, std=0.01, a=-2, b=2)\n",
        "                elif isinstance(m, nn.BatchNorm2d):\n",
        "                    nn.init.constant_(m.weight, 1)\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _transform_input(self, x: Tensor) -> Tensor:\n",
        "        if self.transform_input:\n",
        "            x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
        "            x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
        "            x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
        "            x = torch.cat((x_ch0, x_ch1, x_ch2), 1)\n",
        "        return x\n",
        "\n",
        "    def _forward(self, x: Tensor) -> Tuple[Tensor, Optional[Tensor], Optional[Tensor]]:\n",
        "        # N x 3 x 224 x 224\n",
        "        x = self.conv1(x)\n",
        "        # N x 64 x 112 x 112\n",
        "        x = self.maxpool1(x)\n",
        "        # N x 64 x 56 x 56\n",
        "        x = self.conv2(x)\n",
        "        # N x 64 x 56 x 56\n",
        "        x = self.conv3(x)\n",
        "        # N x 192 x 56 x 56\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        # N x 192 x 28 x 28\n",
        "        x = self.inception3a(x)\n",
        "        # N x 256 x 28 x 28\n",
        "        x = self.inception3b(x)\n",
        "        # N x 480 x 28 x 28\n",
        "        x = self.maxpool3(x)\n",
        "        # N x 480 x 14 x 14\n",
        "        x = self.inception4a(x)\n",
        "        # N x 512 x 14 x 14\n",
        "        aux1: Optional[Tensor] = None\n",
        "        if self.aux1 is not None:\n",
        "            if self.training:\n",
        "                aux1 = self.aux1(x)\n",
        "\n",
        "        x = self.inception4b(x)\n",
        "        # N x 512 x 14 x 14\n",
        "        x = self.inception4c(x)\n",
        "        # N x 512 x 14 x 14\n",
        "        x = self.inception4d(x)\n",
        "        # N x 528 x 14 x 14\n",
        "        aux2: Optional[Tensor] = None\n",
        "        if self.aux2 is not None:\n",
        "            if self.training:\n",
        "                aux2 = self.aux2(x)\n",
        "\n",
        "        x = self.inception4e(x)\n",
        "        # N x 832 x 14 x 14\n",
        "        x = self.maxpool4(x)\n",
        "        # N x 832 x 7 x 7\n",
        "        x = self.inception5a(x)\n",
        "        # N x 832 x 7 x 7\n",
        "        x = self.inception5b(x)\n",
        "        # N x 1024 x 7 x 7\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        # N x 1024 x 1 x 1\n",
        "        x = torch.flatten(x, 1)\n",
        "        # N x 1024\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        # N x 1000 (num_classes)\n",
        "        return x, aux2, aux1\n",
        "\n",
        "    @torch.jit.unused\n",
        "    def eager_outputs(self, x: Tensor, aux2: Tensor, aux1: Optional[Tensor]) -> GoogLeNetOutputs:\n",
        "        if self.training and self.aux_logits:\n",
        "            return _GoogLeNetOutputs(x, aux2, aux1)\n",
        "        else:\n",
        "            return x  # type: ignore[return-value]\n",
        "\n",
        "    def forward(self, x: Tensor) -> GoogLeNetOutputs:\n",
        "        x = self._transform_input(x)\n",
        "        x, aux1, aux2 = self._forward(x)\n",
        "        aux_defined = self.training and self.aux_logits\n",
        "        if torch.jit.is_scripting():\n",
        "            if not aux_defined:\n",
        "                warnings.warn(\"Scripted GoogleNet always returns GoogleNetOutputs Tuple\")\n",
        "            return GoogLeNetOutputs(x, aux2, aux1)\n",
        "        else:\n",
        "            return self.eager_outputs(x, aux2, aux1)\n",
        "\n",
        "\n",
        "class Inception(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        ch1x1: int,\n",
        "        ch3x3red: int,\n",
        "        ch3x3: int,\n",
        "        ch5x5red: int,\n",
        "        ch5x5: int,\n",
        "        pool_proj: int,\n",
        "        conv_block: Optional[Callable[..., nn.Module]] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if conv_block is None:\n",
        "            conv_block = BasicConv2d\n",
        "        self.branch1 = conv_block(in_channels, ch1x1, kernel_size=1)\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            conv_block(in_channels, ch3x3red, kernel_size=1), conv_block(ch3x3red, ch3x3, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.Sequential(\n",
        "            conv_block(in_channels, ch5x5red, kernel_size=1),\n",
        "            # Here, kernel_size=3 instead of kernel_size=5 is a known bug.\n",
        "            # Please see https://github.com/pytorch/vision/issues/906 for details.\n",
        "            conv_block(ch5x5red, ch5x5, kernel_size=3, padding=1),\n",
        "        )\n",
        "\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True),\n",
        "            conv_block(in_channels, pool_proj, kernel_size=1),\n",
        "        )\n",
        "\n",
        "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
        "        branch1 = self.branch1(x)\n",
        "        branch2 = self.branch2(x)\n",
        "        branch3 = self.branch3(x)\n",
        "        branch4 = self.branch4(x)\n",
        "\n",
        "        outputs = [branch1, branch2, branch3, branch4]\n",
        "        return outputs\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        outputs = self._forward(x)\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "\n",
        "class InceptionAux(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        num_classes: int,\n",
        "        conv_block: Optional[Callable[..., nn.Module]] = None,\n",
        "        dropout: float = 0.7,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if conv_block is None:\n",
        "            conv_block = BasicConv2d\n",
        "        self.conv = conv_block(in_channels, 128, kernel_size=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(2048, 1024)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14\n",
        "        x = F.adaptive_avg_pool2d(x, (4, 4))\n",
        "        # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4\n",
        "        x = self.conv(x)\n",
        "        # N x 128 x 4 x 4\n",
        "        x = torch.flatten(x, 1)\n",
        "        # N x 2048\n",
        "        x = F.relu(self.fc1(x), inplace=True)\n",
        "        # N x 1024\n",
        "        x = self.dropout(x)\n",
        "        # N x 1024\n",
        "        x = self.fc2(x)\n",
        "        # N x 1000 (num_classes)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class BasicConv2d(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, **kwargs: Any) -> None:\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
        "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return F.relu(x, inplace=True)\n",
        "\n",
        "\n",
        "class GoogLeNet_Weights(WeightsEnum):\n",
        "    IMAGENET1K_V1 = Weights(\n",
        "        url=\"https://download.pytorch.org/models/googlenet-1378be20.pth\",\n",
        "        transforms=partial(ImageClassification, crop_size=224),\n",
        "        meta={\n",
        "            \"num_params\": 6624904,\n",
        "            \"min_size\": (15, 15),\n",
        "            \"categories\": _IMAGENET_CATEGORIES,\n",
        "            \"recipe\": \"https://github.com/pytorch/vision/tree/main/references/classification#googlenet\",\n",
        "            \"_metrics\": {\n",
        "                \"ImageNet-1K\": {\n",
        "                    \"acc@1\": 69.778,\n",
        "                    \"acc@5\": 89.530,\n",
        "                }\n",
        "            },\n",
        "            \"_docs\": \"\"\"These weights are ported from the original paper.\"\"\",\n",
        "        },\n",
        "    )\n",
        "    DEFAULT = IMAGENET1K_V1\n",
        "\n",
        "\n",
        "@register_model()\n",
        "@handle_legacy_interface(weights=(\"pretrained\", GoogLeNet_Weights.IMAGENET1K_V1))\n",
        "def googlenet(*, weights: Optional[GoogLeNet_Weights] = None, progress: bool = True, **kwargs: Any) -> GoogLeNet:\n",
        "    \"\"\"GoogLeNet (Inception v1) model architecture from\n",
        "    `Going Deeper with Convolutions <http://arxiv.org/abs/1409.4842>`_.\n",
        "\n",
        "    Args:\n",
        "        weights (:class:`~torchvision.models.GoogLeNet_Weights`, optional): The\n",
        "            pretrained weights for the model. See\n",
        "            :class:`~torchvision.models.GoogLeNet_Weights` below for\n",
        "            more details, and possible values. By default, no pre-trained\n",
        "            weights are used.\n",
        "        progress (bool, optional): If True, displays a progress bar of the\n",
        "            download to stderr. Default is True.\n",
        "        **kwargs: parameters passed to the ``torchvision.models.GoogLeNet``\n",
        "            base class. Please refer to the `source code\n",
        "            <https://github.com/pytorch/vision/blob/main/torchvision/models/googlenet.py>`_\n",
        "            for more details about this class.\n",
        "    .. autoclass:: torchvision.models.GoogLeNet_Weights\n",
        "        :members:\n",
        "    \"\"\"\n",
        "    weights = GoogLeNet_Weights.verify(weights)\n",
        "\n",
        "    original_aux_logits = kwargs.get(\"aux_logits\", False)\n",
        "    if weights is not None:\n",
        "        if \"transform_input\" not in kwargs:\n",
        "            _ovewrite_named_param(kwargs, \"transform_input\", True)\n",
        "        _ovewrite_named_param(kwargs, \"aux_logits\", True)\n",
        "        _ovewrite_named_param(kwargs, \"init_weights\", False)\n",
        "        _ovewrite_named_param(kwargs, \"num_classes\", len(weights.meta[\"categories\"]))\n",
        "\n",
        "    model = GoogLeNet(**kwargs)\n",
        "\n",
        "    if weights is not None:\n",
        "        model.load_state_dict(weights.get_state_dict(progress=progress))\n",
        "        if not original_aux_logits:\n",
        "            model.aux_logits = False\n",
        "            model.aux1 = None  # type: ignore[assignment]\n",
        "            model.aux2 = None  # type: ignore[assignment]\n",
        "        else:\n",
        "            warnings.warn(\n",
        "                \"auxiliary heads in the pretrained googlenet model are NOT pretrained, so make sure to train them\"\n",
        "            )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# The dictionary below is internal implementation detail and will be removed in v0.15\n",
        "from ._utils import _ModelURLs\n",
        "\n",
        "\n",
        "model_urls = _ModelURLs(\n",
        "    {\n",
        "        # GoogLeNet ported from TensorFlow\n",
        "        \"googlenet\": GoogLeNet_Weights.IMAGENET1K_V1.url,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji2pJ5hz3Uwi"
      },
      "source": [
        " # STL10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP9kN1l9ekm1",
        "outputId": "7ccccad9-fe45-4979-e4b4-0fc240534bbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['Classifier.0.weight', 'Classifier.0.bias', 'Classifier.3.weight', 'Classifier.3.bias', 'Classifier.6.weight', 'Classifier.6.bias'], unexpected_keys=['classifier.0.weight', 'classifier.0.bias', 'classifier.3.weight', 'classifier.3.bias', 'classifier.6.weight', 'classifier.6.bias'])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transform=transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5,),(0.5,0.5,0.5)),\n",
        "\ttransforms.Resize([227, 227])\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Download training data from open datasets.\n",
        "train_set = datasets.STL10(\n",
        "    root=\"~/data/STL10/\",\n",
        "    split ='train',\n",
        "    download=True,\n",
        "    transform=transform, # transform,\n",
        ")\n",
        "trainloader=torch.utils.data.DataLoader(\n",
        "\ttrain_set,\n",
        "\tbatch_size=60,\n",
        "\tshuffle=True,\n",
        "\tpin_memory=True,\n",
        "    num_workers=8\n",
        "\t)\n",
        "\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_set = datasets.STL10(\n",
        "    root=\"~/data/STL10/\",\n",
        "    split ='test',\n",
        "    download=True,\n",
        "    transform=transform, # transform,\n",
        ")\n",
        "testloader=torch.utils.data.DataLoader(\n",
        "\ttest_set,\n",
        "\tbatch_size=60,\n",
        "\tshuffle=False,\n",
        "    pin_memory=True,\n",
        "    num_workers=8\n",
        "\t)\n",
        "\n",
        "# test_data_iter=iter(testloader)\n",
        "# test_image,test_label=test_data_iter.next()\n",
        "test_num  = len(test_set)\n",
        "train_steps = len(trainloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92UjNaPq3hF6"
      },
      "source": [
        "# loss and optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bigYof8sekm3"
      },
      "outputs": [],
      "source": [
        "# 定义一个损失函数\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# 定义一个优化器\n",
        "# optimizer = torch.optim.Adam(model.parameters(),lr=0.005)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "# optimizer = torch.optim.SGD(model.parameters(),lr=0.001)\n",
        "\n",
        "epochs = 40\n",
        "\n",
        "save_path= './GoogLeNet.pth'\n",
        "best_acc = 0.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcasfhHN4rGn"
      },
      "source": [
        "# Transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B16aNteM4mlH"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# from torchvision import models\n",
        "# pretrained_googlenet = models.googlenet(pretrained=True)\n",
        "# torch.save(pretrained_googlenet.state_dict(), save_path)\n",
        "\n",
        "model = VGG16(num_classes=10, init_weights=True).to(device)\n",
        "model.load_state_dict(torch.load(save_path),strict=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06G0oqoc3p_d"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JpLHjMKRekm4",
        "outputId": "1691b337-5917-4846-c943-2ecf27a4700d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch[1/40] loss:1.502: 100%|██████████| 84/84 [01:12<00:00,  1.16it/s]\n",
            "100%|██████████| 134/134 [00:38<00:00,  3.49it/s]\n",
            "[epoch 1] train_loss: 2.189  val_accuracy: 0.696\n",
            "train epoch[2/40] loss:1.107: 100%|██████████| 84/84 [01:10<00:00,  1.19it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.27it/s]\n",
            "[epoch 2] train_loss: 1.365  val_accuracy: 0.832\n",
            "train epoch[3/40] loss:0.932: 100%|██████████| 84/84 [01:09<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.33it/s]\n",
            "[epoch 3] train_loss: 0.854  val_accuracy: 0.872\n",
            "train epoch[4/40] loss:0.429: 100%|██████████| 84/84 [01:09<00:00,  1.21it/s]\n",
            "100%|██████████| 134/134 [00:39<00:00,  3.38it/s]\n",
            "[epoch 4] train_loss: 0.623  val_accuracy: 0.902\n",
            "train epoch[5/40] loss:0.225: 100%|██████████| 84/84 [01:10<00:00,  1.19it/s]\n",
            "100%|██████████| 134/134 [00:41<00:00,  3.27it/s]\n",
            "[epoch 5] train_loss: 0.502  val_accuracy: 0.913\n",
            "train epoch[6/40] loss:0.206: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.30it/s]\n",
            "[epoch 6] train_loss: 0.390  val_accuracy: 0.920\n",
            "train epoch[7/40] loss:0.293: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.31it/s]\n",
            "[epoch 7] train_loss: 0.339  val_accuracy: 0.924\n",
            "train epoch[8/40] loss:0.142: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.30it/s]\n",
            "[epoch 8] train_loss: 0.281  val_accuracy: 0.925\n",
            "train epoch[9/40] loss:0.233: 100%|██████████| 84/84 [01:09<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.33it/s]\n",
            "[epoch 9] train_loss: 0.267  val_accuracy: 0.930\n",
            "train epoch[10/40] loss:0.200: 100%|██████████| 84/84 [01:10<00:00,  1.19it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.33it/s]\n",
            "[epoch 10] train_loss: 0.233  val_accuracy: 0.933\n",
            "train epoch[11/40] loss:0.330: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.33it/s]\n",
            "[epoch 11] train_loss: 0.208  val_accuracy: 0.934\n",
            "train epoch[12/40] loss:0.107: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.34it/s]\n",
            "[epoch 12] train_loss: 0.177  val_accuracy: 0.937\n",
            "train epoch[13/40] loss:0.100: 100%|██████████| 84/84 [01:10<00:00,  1.19it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.30it/s]\n",
            "[epoch 13] train_loss: 0.157  val_accuracy: 0.937\n",
            "train epoch[14/40] loss:0.261: 100%|██████████| 84/84 [01:10<00:00,  1.19it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.33it/s]\n",
            "[epoch 14] train_loss: 0.153  val_accuracy: 0.939\n",
            "train epoch[15/40] loss:0.150: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.32it/s]\n",
            "[epoch 15] train_loss: 0.138  val_accuracy: 0.939\n",
            "train epoch[16/40] loss:0.037: 100%|██████████| 84/84 [01:10<00:00,  1.18it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.33it/s]\n",
            "[epoch 16] train_loss: 0.120  val_accuracy: 0.942\n",
            "train epoch[17/40] loss:0.138: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.32it/s]\n",
            "[epoch 17] train_loss: 0.122  val_accuracy: 0.940\n",
            "train epoch[18/40] loss:0.118: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.29it/s]\n",
            "[epoch 18] train_loss: 0.113  val_accuracy: 0.941\n",
            "train epoch[19/40] loss:0.128: 100%|██████████| 84/84 [01:09<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:41<00:00,  3.24it/s]\n",
            "[epoch 19] train_loss: 0.093  val_accuracy: 0.940\n",
            "train epoch[20/40] loss:0.047: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.31it/s]\n",
            "[epoch 20] train_loss: 0.086  val_accuracy: 0.941\n",
            "train epoch[21/40] loss:0.039: 100%|██████████| 84/84 [01:09<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.32it/s]\n",
            "[epoch 21] train_loss: 0.074  val_accuracy: 0.942\n",
            "train epoch[22/40] loss:0.223: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.33it/s]\n",
            "[epoch 22] train_loss: 0.070  val_accuracy: 0.939\n",
            "train epoch[23/40] loss:0.031: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.32it/s]\n",
            "[epoch 23] train_loss: 0.065  val_accuracy: 0.943\n",
            "train epoch[24/40] loss:0.330: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.28it/s]\n",
            "[epoch 24] train_loss: 0.068  val_accuracy: 0.943\n",
            "train epoch[25/40] loss:0.010: 100%|██████████| 84/84 [01:10<00:00,  1.19it/s]\n",
            "100%|██████████| 134/134 [00:41<00:00,  3.27it/s]\n",
            "[epoch 25] train_loss: 0.064  val_accuracy: 0.941\n",
            "train epoch[26/40] loss:0.012: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.30it/s]\n",
            "[epoch 26] train_loss: 0.061  val_accuracy: 0.943\n",
            "train epoch[27/40] loss:0.027: 100%|██████████| 84/84 [01:10<00:00,  1.19it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.28it/s]\n",
            "[epoch 27] train_loss: 0.048  val_accuracy: 0.943\n",
            "train epoch[28/40] loss:0.006: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.30it/s]\n",
            "[epoch 28] train_loss: 0.047  val_accuracy: 0.942\n",
            "train epoch[29/40] loss:0.050:  10%|▉         | 8/84 [00:09<01:30,  1.20s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-786ba45e21bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtrain_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train epoch[{}/{}] loss:{:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "        # train\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        train_bar = tqdm(trainloader, file=sys.stdout)\n",
        "        for step, data in enumerate(train_bar):\n",
        "            images, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images.to(device))\n",
        "            loss = loss_fn(outputs, labels.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,epochs,loss)\n",
        "\n",
        "        # validate\n",
        "        model.eval()\n",
        "        acc = 0.0  # accumulate accurate number / epoch\n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(testloader, file=sys.stdout) # show progress\n",
        "            for val_data in val_bar:\n",
        "                val_images, val_labels = val_data\n",
        "                outputs = model(val_images.to(device))\n",
        "                predict_y = torch.max(outputs, dim=1)[1]\n",
        "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
        "\n",
        "        val_accurate = acc / test_num\n",
        "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
        "              (epoch + 1, running_loss / train_steps, val_accurate))\n",
        "\n",
        "        if val_accurate > best_acc:\n",
        "            best_acc = val_accurate\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import typing\n",
        "Id = typing.NewType(\"Id\", int)\n",
        "a = Id(2020)\n",
        "type(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n"
          ]
        }
      ],
      "source": [
        "def f(a: str, b:int) -> str:\n",
        "    return a * b\n",
        "\n",
        "print(f(4,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "from typing import Callable\n",
        "def f(a: int) -> str:\n",
        "    return str(a)\n",
        "def callback(a: int, func: Callable[[int], str]) -> str:\n",
        "    return func(a)\n",
        "print(callback(2, f))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('ryan': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e70b0d8493b7f59e214a43b868537ebeafe12cb89daa279090c57b89e62c1c99"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
