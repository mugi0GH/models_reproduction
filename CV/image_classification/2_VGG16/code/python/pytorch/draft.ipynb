{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fNeXLdf_ekmq"
      },
      "outputs": [],
      "source": [
        "import torch,sys,os\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzq0Y5WX2-NU"
      },
      "source": [
        "# Self reproduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRXGP-qt3A_E"
      },
      "outputs": [],
      "source": [
        "from typing import Optional,Callable\n",
        "\n",
        "class GoogLeNet_v1(nn.Module):\n",
        "    def __init__(self,num_classes=1000,init_weights=False):\n",
        "        super(GoogLeNet_v1,self).__init__()\n",
        "\n",
        "        self.Conv = nn.Sequential(\n",
        "            # 使用7x7的卷积核（滑动步长2，padding为3），64通道，输出为112x112x64，卷积后进行ReLU操作\n",
        "            nn.Conv2d(kernel_size=7,stride=2,padding=3,out_channels=64,in_channels=3), \n",
        "            nn.ReLU(),\n",
        "\n",
        "            # 经过3x3的max pooling（步长为2），输出为((112 - 3+1)/2)+1=56，即56x56x64，再进行ReLU操作\n",
        "            nn.MaxPool2d(stride=2,kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.LocalResponseNorm(size=5, k=2, alpha=1e-4, beta=0.75),\n",
        "\n",
        "            # 使用3x3的卷积核（滑动步长为1，padding为1），192通道，输出为56x56x192，卷积后进行ReLU操作\n",
        "\n",
        "            nn.Conv2d(in_channels=64,out_channels=64,kernel_size=1),\n",
        "            nn.LocalResponseNorm(size=5, k=2, alpha=1e-4, beta=0.75),\n",
        "            nn.Conv2d(in_channels=64,out_channels=192,kernel_size=3,stride=1),\n",
        "            nn.LocalResponseNorm(size=5, k=2, alpha=1e-4, beta=0.75),\n",
        "            nn.ReLU(),\n",
        "            # 经过3x3的max pooling（步长为2），输出为((56 - 3+1)/2)+1=28，即28x28x192，再进行ReLU操作\n",
        "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.Inception_3a = Inception(in_channels=64,ch1x1=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x= self.Conv(x)\n",
        "        y\n",
        "        return y\n",
        "\n",
        "\n",
        "class Inception(nn.Module):\n",
        "    def __init__(self,\n",
        "        in_channels: int,\n",
        "        ch1x1: int,\n",
        "        ch3x3red: int,\n",
        "        ch3x3: int,\n",
        "        ch5x5red: int,\n",
        "        ch5x5: int,\n",
        "        pool_proj: int,\n",
        "        conv_block: Optional[Callable[..., nn.Module]] = None,) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Optional,Callable\n",
        "from typing import Any, Callable, List, Optional, Tuple\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GoogLeNet_v1(nn.Module):\n",
        "    def __init__(self,num_classes=1000,init_weights=False,blocks: Optional[List[Callable[..., nn.Module]]] = None):\n",
        "        super(GoogLeNet_v1,self).__init__()\n",
        "\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "        if blocks is None:\n",
        "            blocks = [BasicConv2d, Inception, InceptionAux]\n",
        "        inception_block = blocks[1]\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.6)\n",
        "\n",
        "        self.Conv = nn.Sequential(\n",
        "            # 使用7x7的卷积核（滑动步长2，padding为3），64通道，输出为112x112x64，卷积后进行ReLU操作\n",
        "            nn.Conv2d(kernel_size=7,stride=2,padding=3,out_channels=64,in_channels=3), \n",
        "            nn.ReLU(),\n",
        "\n",
        "            # 经过3x3的max pooling（步长为2），输出为((112 - 3+1)/2)+1=56，即56x56x64，再进行ReLU操作\n",
        "            nn.MaxPool2d(stride=2,kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.LocalResponseNorm(size=5, k=2, alpha=1e-4, beta=0.75),\n",
        "\n",
        "            # 使用3x3的卷积核（滑动步长为1，padding为1），192通道，输出为56x56x192，卷积后进行ReLU操作\n",
        "\n",
        "            nn.Conv2d(in_channels=64,out_channels=64,kernel_size=1),\n",
        "            nn.LocalResponseNorm(size=5, k=2, alpha=1e-4, beta=0.75),\n",
        "            nn.Conv2d(in_channels=64,out_channels=192,kernel_size=3,stride=1),\n",
        "            nn.LocalResponseNorm(size=5, k=2, alpha=1e-4, beta=0.75),\n",
        "            nn.ReLU(),\n",
        "            # 经过3x3的max pooling（步长为2），输出为((56 - 3+1)/2)+1=28，即28x28x192，再进行ReLU操作\n",
        "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.Inception_3a = inception_block(in_channels = 192,ch1x1= 64,ch3x3red= 96,ch3x3= 128,ch5x5red= 16,ch5x5= 32,pool_proj= 32)\n",
        "        self.Inception_3b = inception_block(in_channels = 256,ch1x1= 128,ch3x3red= 128,ch3x3= 192,ch5x5red= 32,ch5x5= 96,pool_proj= 64)\n",
        "\n",
        "        self.Inception_4a = inception_block(in_channels = 480,ch1x1= 192,ch3x3red= 96,ch3x3= 208,ch5x5red= 16,ch5x5= 48,pool_proj= 64)\n",
        "        self.Inception_4b = inception_block(in_channels = 512,ch1x1= 160,ch3x3red= 112,ch3x3= 224,ch5x5red= 24,ch5x5= 64,pool_proj= 64)\n",
        "        self.Inception_4c = inception_block(in_channels = 512,ch1x1= 128,ch3x3red= 128,ch3x3= 256,ch5x5red= 24,ch5x5= 64,pool_proj= 64)\n",
        "        self.Inception_4d = inception_block(in_channels = 512,ch1x1= 112,ch3x3red= 144,ch3x3= 288,ch5x5red= 32,ch5x5= 64,pool_proj= 64)\n",
        "        self.Inception_4e = inception_block(in_channels = 528,ch1x1= 256,ch3x3red= 160,ch3x3= 320,ch5x5red= 32,ch5x5= 128,pool_proj= 128)\n",
        "\n",
        "        self.Inception_5a = inception_block(in_channels = 832,ch1x1= 256,ch3x3red= 160,ch3x3= 320,ch5x5red= 32,ch5x5= 128,pool_proj= 128)\n",
        "        self.Inception_5b = inception_block(in_channels = 832,ch1x1= 384,ch3x3red= 192,ch3x3= 384,ch5x5red= 48,ch5x5= 128,pool_proj= 128)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x= self.Conv(x)\n",
        "\n",
        "        x= self.Inception_3a(x)\n",
        "        x= self.Inception_3b(x)\n",
        "        x= nn.MaxPool2d(kernel_size=3,stride=2)\n",
        "\n",
        "        x= self.Inception_4a(x)\n",
        "        x= self.Inception_4b(x)\n",
        "        x= self.Inception_4c(x)\n",
        "        x= self.Inception_4d(x)\n",
        "        x= self.Inception_4e(x)\n",
        "        x= nn.MaxPool2d(kernel_size=3,stride=2)\n",
        "\n",
        "        x= self.Inception_5a(x)     \n",
        "        x= self.Inception_5b(x)\n",
        "        x = nn.AvgPool2d(kernel_size=7,stride=1)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        y = self.fc(x)\n",
        "        return y\n",
        "\n",
        "\n",
        "\n",
        "class Inception(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        ch1x1: int,\n",
        "        ch3x3red: int,\n",
        "        ch3x3: int,\n",
        "        ch5x5red: int,\n",
        "        ch5x5: int,\n",
        "        pool_proj: int,\n",
        "        conv_block: Optional[Callable[..., nn.Module]] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if conv_block is None:\n",
        "            conv_block = BasicConv2d\n",
        "        self.branch1 = conv_block(in_channels, ch1x1, kernel_size=1)\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            conv_block(in_channels, ch3x3red, kernel_size=1), \n",
        "            conv_block(ch3x3red, ch3x3, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.Sequential(\n",
        "            conv_block(in_channels, ch5x5red, kernel_size=1),\n",
        "            # Here, kernel_size=3 instead of kernel_size=5 is a known bug.\n",
        "            # Please see https://github.com/pytorch/vision/issues/906 for details.\n",
        "            conv_block(ch5x5red, ch5x5, kernel_size=3, padding=1),\n",
        "        )\n",
        "\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True),\n",
        "            conv_block(in_channels, pool_proj, kernel_size=1),\n",
        "        )\n",
        "\n",
        "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
        "        branch1 = self.branch1(x)\n",
        "        branch2 = self.branch2(x)\n",
        "        branch3 = self.branch3(x)\n",
        "        branch4 = self.branch4(x)\n",
        "\n",
        "        outputs = [branch1, branch2, branch3, branch4]\n",
        "        return outputs\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        outputs = self._forward(x)\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "        \n",
        "\n",
        "class BasicConv2d(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, **kwargs: Any) -> None:\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
        "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return F.relu(x, inplace=True)\n",
        "\n",
        "class InceptionAux(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        num_classes: int,\n",
        "        conv_block: Optional[Callable[..., nn.Module]] = None,\n",
        "        dropout: float = 0.7,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if conv_block is None:\n",
        "            conv_block = BasicConv2d\n",
        "        self.conv = conv_block(in_channels, 128, kernel_size=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(2048, 1024)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14\n",
        "        x = F.adaptive_avg_pool2d(x, (4, 4))\n",
        "        # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4\n",
        "        x = self.conv(x)\n",
        "        # N x 128 x 4 x 4\n",
        "        x = torch.flatten(x, 1)\n",
        "        # N x 2048\n",
        "        x = F.relu(self.fc1(x), inplace=True)\n",
        "        # N x 1024\n",
        "        x = self.dropout(x)\n",
        "        # N x 1024\n",
        "        x = self.fc2(x)\n",
        "        # N x 1000 (num_classes)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GoogLeNet_v1(\n",
              "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0.6, inplace=False)\n",
              "  (Conv): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): ReLU()\n",
              "    (4): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
              "    (5): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (6): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
              "    (7): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (8): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
              "    (9): ReLU()\n",
              "    (10): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (11): ReLU()\n",
              "  )\n",
              "  (Inception_3a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (Inception_3b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (Inception_4a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (Inception_4b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (Inception_4c): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (Inception_4d): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(528, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(528, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(528, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (Inception_4e): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (Inception_5a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (Inception_5b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(1024, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = GoogLeNet_v1(num_classes= 10,init_weights=True)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk2GUtd324J5"
      },
      "source": [
        "# Pytorch Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na3tP_1Jekmy",
        "outputId": "114d18c2-3381-4d00-f6aa-2c3e1f765e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji2pJ5hz3Uwi"
      },
      "source": [
        " # STL10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP9kN1l9ekm1",
        "outputId": "7ccccad9-fe45-4979-e4b4-0fc240534bbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['Classifier.0.weight', 'Classifier.0.bias', 'Classifier.3.weight', 'Classifier.3.bias', 'Classifier.6.weight', 'Classifier.6.bias'], unexpected_keys=['classifier.0.weight', 'classifier.0.bias', 'classifier.3.weight', 'classifier.3.bias', 'classifier.6.weight', 'classifier.6.bias'])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transform=transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5,),(0.5,0.5,0.5)),\n",
        "\ttransforms.Resize([224, 224])\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Download training data from open datasets.\n",
        "train_set = datasets.STL10(\n",
        "    root=\"~/data/STL10/\",\n",
        "    split ='train',\n",
        "    download=True,\n",
        "    transform=transform, # transform,\n",
        ")\n",
        "trainloader=torch.utils.data.DataLoader(\n",
        "\ttrain_set,\n",
        "\tbatch_size=60,\n",
        "\tshuffle=True,\n",
        "\tpin_memory=True,\n",
        "    num_workers=8\n",
        "\t)\n",
        "\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_set = datasets.STL10(\n",
        "    root=\"~/data/STL10/\",\n",
        "    split ='test',\n",
        "    download=True,\n",
        "    transform=transform, # transform,\n",
        ")\n",
        "testloader=torch.utils.data.DataLoader(\n",
        "\ttest_set,\n",
        "\tbatch_size=60,\n",
        "\tshuffle=False,\n",
        "    pin_memory=True,\n",
        "    num_workers=8\n",
        "\t)\n",
        "\n",
        "# test_data_iter=iter(testloader)\n",
        "# test_image,test_label=test_data_iter.next()\n",
        "test_num  = len(test_set)\n",
        "train_steps = len(trainloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92UjNaPq3hF6"
      },
      "source": [
        "# loss and optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bigYof8sekm3"
      },
      "outputs": [],
      "source": [
        "# 定义一个损失函数\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# 定义一个优化器\n",
        "# optimizer = torch.optim.Adam(model.parameters(),lr=0.005)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "# optimizer = torch.optim.SGD(model.parameters(),lr=0.001)\n",
        "\n",
        "epochs = 40\n",
        "\n",
        "save_path= './VGG16.pth'\n",
        "best_acc = 0.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcasfhHN4rGn"
      },
      "source": [
        "# Transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B16aNteM4mlH"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# from torchvision import models\n",
        "# pretrained_VGG16 = models.vgg16(pretrained=True)\n",
        "# torch.save(pretrained_VGG16.state_dict(), save_path)\n",
        "\n",
        "model = VGG16(num_classes=10, init_weights=True).to(device)\n",
        "model.load_state_dict(torch.load('./VGG16.pth'),strict=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06G0oqoc3p_d"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JpLHjMKRekm4",
        "outputId": "1691b337-5917-4846-c943-2ecf27a4700d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch[1/40] loss:1.502: 100%|██████████| 84/84 [01:12<00:00,  1.16it/s]\n",
            "100%|██████████| 134/134 [00:38<00:00,  3.49it/s]\n",
            "[epoch 1] train_loss: 2.189  val_accuracy: 0.696\n",
            "train epoch[2/40] loss:1.107: 100%|██████████| 84/84 [01:10<00:00,  1.19it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.27it/s]\n",
            "[epoch 2] train_loss: 1.365  val_accuracy: 0.832\n",
            "train epoch[3/40] loss:0.932: 100%|██████████| 84/84 [01:09<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.33it/s]\n",
            "[epoch 3] train_loss: 0.854  val_accuracy: 0.872\n",
            "train epoch[4/40] loss:0.429: 100%|██████████| 84/84 [01:09<00:00,  1.21it/s]\n",
            "100%|██████████| 134/134 [00:39<00:00,  3.38it/s]\n",
            "[epoch 4] train_loss: 0.623  val_accuracy: 0.902\n",
            "train epoch[5/40] loss:0.225: 100%|██████████| 84/84 [01:10<00:00,  1.19it/s]\n",
            "100%|██████████| 134/134 [00:41<00:00,  3.27it/s]\n",
            "[epoch 5] train_loss: 0.502  val_accuracy: 0.913\n",
            "train epoch[6/40] loss:0.206: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.30it/s]\n",
            "[epoch 6] train_loss: 0.390  val_accuracy: 0.920\n",
            "train epoch[7/40] loss:0.293: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.31it/s]\n",
            "[epoch 7] train_loss: 0.339  val_accuracy: 0.924\n",
            "train epoch[8/40] loss:0.142: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.30it/s]\n",
            "[epoch 8] train_loss: 0.281  val_accuracy: 0.925\n",
            "train epoch[9/40] loss:0.233: 100%|██████████| 84/84 [01:09<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.33it/s]\n",
            "[epoch 9] train_loss: 0.267  val_accuracy: 0.930\n",
            "train epoch[10/40] loss:0.200: 100%|██████████| 84/84 [01:10<00:00,  1.19it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.33it/s]\n",
            "[epoch 10] train_loss: 0.233  val_accuracy: 0.933\n",
            "train epoch[11/40] loss:0.330: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.33it/s]\n",
            "[epoch 11] train_loss: 0.208  val_accuracy: 0.934\n",
            "train epoch[12/40] loss:0.107: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.34it/s]\n",
            "[epoch 12] train_loss: 0.177  val_accuracy: 0.937\n",
            "train epoch[13/40] loss:0.100: 100%|██████████| 84/84 [01:10<00:00,  1.19it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.30it/s]\n",
            "[epoch 13] train_loss: 0.157  val_accuracy: 0.937\n",
            "train epoch[14/40] loss:0.261: 100%|██████████| 84/84 [01:10<00:00,  1.19it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.33it/s]\n",
            "[epoch 14] train_loss: 0.153  val_accuracy: 0.939\n",
            "train epoch[15/40] loss:0.150: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.32it/s]\n",
            "[epoch 15] train_loss: 0.138  val_accuracy: 0.939\n",
            "train epoch[16/40] loss:0.037: 100%|██████████| 84/84 [01:10<00:00,  1.18it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.33it/s]\n",
            "[epoch 16] train_loss: 0.120  val_accuracy: 0.942\n",
            "train epoch[17/40] loss:0.138: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.32it/s]\n",
            "[epoch 17] train_loss: 0.122  val_accuracy: 0.940\n",
            "train epoch[18/40] loss:0.118: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.29it/s]\n",
            "[epoch 18] train_loss: 0.113  val_accuracy: 0.941\n",
            "train epoch[19/40] loss:0.128: 100%|██████████| 84/84 [01:09<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:41<00:00,  3.24it/s]\n",
            "[epoch 19] train_loss: 0.093  val_accuracy: 0.940\n",
            "train epoch[20/40] loss:0.047: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.31it/s]\n",
            "[epoch 20] train_loss: 0.086  val_accuracy: 0.941\n",
            "train epoch[21/40] loss:0.039: 100%|██████████| 84/84 [01:09<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.32it/s]\n",
            "[epoch 21] train_loss: 0.074  val_accuracy: 0.942\n",
            "train epoch[22/40] loss:0.223: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.33it/s]\n",
            "[epoch 22] train_loss: 0.070  val_accuracy: 0.939\n",
            "train epoch[23/40] loss:0.031: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.32it/s]\n",
            "[epoch 23] train_loss: 0.065  val_accuracy: 0.943\n",
            "train epoch[24/40] loss:0.330: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.28it/s]\n",
            "[epoch 24] train_loss: 0.068  val_accuracy: 0.943\n",
            "train epoch[25/40] loss:0.010: 100%|██████████| 84/84 [01:10<00:00,  1.19it/s]\n",
            "100%|██████████| 134/134 [00:41<00:00,  3.27it/s]\n",
            "[epoch 25] train_loss: 0.064  val_accuracy: 0.941\n",
            "train epoch[26/40] loss:0.012: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.30it/s]\n",
            "[epoch 26] train_loss: 0.061  val_accuracy: 0.943\n",
            "train epoch[27/40] loss:0.027: 100%|██████████| 84/84 [01:10<00:00,  1.19it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.28it/s]\n",
            "[epoch 27] train_loss: 0.048  val_accuracy: 0.943\n",
            "train epoch[28/40] loss:0.006: 100%|██████████| 84/84 [01:10<00:00,  1.20it/s]\n",
            "100%|██████████| 134/134 [00:40<00:00,  3.30it/s]\n",
            "[epoch 28] train_loss: 0.047  val_accuracy: 0.942\n",
            "train epoch[29/40] loss:0.050:  10%|▉         | 8/84 [00:09<01:30,  1.20s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-786ba45e21bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtrain_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train epoch[{}/{}] loss:{:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "        # train\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        train_bar = tqdm(trainloader, file=sys.stdout)\n",
        "        for step, data in enumerate(train_bar):\n",
        "            images, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images.to(device))\n",
        "            loss = loss_fn(outputs, labels.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,epochs,loss)\n",
        "\n",
        "        # validate\n",
        "        model.eval()\n",
        "        acc = 0.0  # accumulate accurate number / epoch\n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(testloader, file=sys.stdout) # show progress\n",
        "            for val_data in val_bar:\n",
        "                val_images, val_labels = val_data\n",
        "                outputs = model(val_images.to(device))\n",
        "                predict_y = torch.max(outputs, dim=1)[1]\n",
        "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
        "\n",
        "        val_accurate = acc / test_num\n",
        "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
        "              (epoch + 1, running_loss / train_steps, val_accurate))\n",
        "\n",
        "        if val_accurate > best_acc:\n",
        "            best_acc = val_accurate\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "print('Finished Training')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('ryan': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e70b0d8493b7f59e214a43b868537ebeafe12cb89daa279090c57b89e62c1c99"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
