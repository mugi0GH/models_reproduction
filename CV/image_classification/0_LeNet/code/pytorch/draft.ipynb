{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,sys,os\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "from torchvision.transforms import ToTensor,transforms\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "from turtle import forward\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes, init_weights=False) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=400,out_features=120),\n",
    "            nn.Linear(in_features=120,out_features=84),\n",
    "            nn.Linear(in_features=84,out_features=num_classes)\n",
    "            )\n",
    "            \n",
    "        if init_weights:\n",
    "            self.weight_init()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        y = self.out(x)\n",
    "        return y\n",
    "\n",
    "    def weight_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='tanh')\n",
    "                # nn.init.normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "LeNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (3): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "train_set = datasets.CIFAR10(\n",
    "    root=\"~/data/CIFAR10/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor() # transform,\n",
    ")\n",
    "trainloader=torch.utils.data.DataLoader(\n",
    "\ttrain_set,\n",
    "\tbatch_size=144,\n",
    "\tshuffle=False,\n",
    "\tpin_memory=True,\n",
    "    num_workers=8\n",
    "\t)\n",
    "\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_set = datasets.CIFAR10(\n",
    "    root=\"~/data/CIFAR10/\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor() # transform,\n",
    ")\n",
    "testloader=torch.utils.data.DataLoader(\n",
    "\ttest_set,\n",
    "\tbatch_size=10000,\n",
    "\tshuffle=False,\n",
    "\tpin_memory=True,\n",
    "    num_workers=8\n",
    "\t)\n",
    "\n",
    "test_data_iter=iter(testloader)\n",
    "test_image,test_label=test_data_iter.next()\n",
    "test_num  = len(test_set)\n",
    "\n",
    "train_steps = len(trainloader)\n",
    "\n",
    "model = LeNet(num_classes=10,init_weights=True).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义一个优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "epochs = 40\n",
    "\n",
    "save_path= './LeNet.pth'\n",
    "best_acc = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch[1/40] loss:2.221: 100%|██████████| 348/348 [00:04<00:00, 83.40it/s] \n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "[epoch 1] train_loss: 1.949  val_accuracy: 0.341\n",
      "train epoch[2/40] loss:2.067: 100%|██████████| 348/348 [00:03<00:00, 95.58it/s] \n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "[epoch 2] train_loss: 1.738  val_accuracy: 0.399\n",
      "train epoch[3/40] loss:1.915: 100%|██████████| 348/348 [00:03<00:00, 92.90it/s] \n",
      "100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "[epoch 3] train_loss: 1.632  val_accuracy: 0.429\n",
      "train epoch[4/40] loss:1.809: 100%|██████████| 348/348 [00:03<00:00, 97.63it/s] \n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "[epoch 4] train_loss: 1.567  val_accuracy: 0.445\n",
      "train epoch[5/40] loss:1.761: 100%|██████████| 348/348 [00:03<00:00, 102.18it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "[epoch 5] train_loss: 1.517  val_accuracy: 0.457\n",
      "train epoch[6/40] loss:1.707: 100%|██████████| 348/348 [00:03<00:00, 101.81it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "[epoch 6] train_loss: 1.475  val_accuracy: 0.469\n",
      "train epoch[7/40] loss:1.656: 100%|██████████| 348/348 [00:03<00:00, 102.05it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "[epoch 7] train_loss: 1.444  val_accuracy: 0.483\n",
      "train epoch[8/40] loss:1.611: 100%|██████████| 348/348 [00:03<00:00, 102.79it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "[epoch 8] train_loss: 1.420  val_accuracy: 0.490\n",
      "train epoch[9/40] loss:1.573: 100%|██████████| 348/348 [00:03<00:00, 99.05it/s] \n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "[epoch 9] train_loss: 1.401  val_accuracy: 0.497\n",
      "train epoch[10/40] loss:1.542: 100%|██████████| 348/348 [00:03<00:00, 103.59it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "[epoch 10] train_loss: 1.385  val_accuracy: 0.500\n",
      "train epoch[11/40] loss:1.517: 100%|██████████| 348/348 [00:03<00:00, 101.04it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "[epoch 11] train_loss: 1.371  val_accuracy: 0.502\n",
      "train epoch[12/40] loss:1.495: 100%|██████████| 348/348 [00:03<00:00, 101.79it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "[epoch 12] train_loss: 1.359  val_accuracy: 0.507\n",
      "train epoch[13/40] loss:1.477: 100%|██████████| 348/348 [00:03<00:00, 103.27it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "[epoch 13] train_loss: 1.348  val_accuracy: 0.512\n",
      "train epoch[14/40] loss:1.460: 100%|██████████| 348/348 [00:03<00:00, 102.46it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "[epoch 14] train_loss: 1.338  val_accuracy: 0.515\n",
      "train epoch[15/40] loss:1.446: 100%|██████████| 348/348 [00:03<00:00, 100.70it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "[epoch 15] train_loss: 1.328  val_accuracy: 0.516\n",
      "train epoch[16/40] loss:1.435: 100%|██████████| 348/348 [00:03<00:00, 100.87it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "[epoch 16] train_loss: 1.319  val_accuracy: 0.519\n",
      "train epoch[17/40] loss:1.426: 100%|██████████| 348/348 [00:03<00:00, 97.83it/s] \n",
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "[epoch 17] train_loss: 1.310  val_accuracy: 0.523\n",
      "train epoch[18/40] loss:1.419: 100%|██████████| 348/348 [00:03<00:00, 100.44it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "[epoch 18] train_loss: 1.302  val_accuracy: 0.524\n",
      "train epoch[19/40] loss:1.414: 100%|██████████| 348/348 [00:03<00:00, 101.05it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "[epoch 19] train_loss: 1.295  val_accuracy: 0.525\n",
      "train epoch[20/40] loss:1.410: 100%|██████████| 348/348 [00:03<00:00, 104.26it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "[epoch 20] train_loss: 1.287  val_accuracy: 0.527\n",
      "train epoch[21/40] loss:1.404: 100%|██████████| 348/348 [00:03<00:00, 100.40it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "[epoch 21] train_loss: 1.280  val_accuracy: 0.530\n",
      "train epoch[22/40] loss:1.396: 100%|██████████| 348/348 [00:03<00:00, 98.73it/s] \n",
      "100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "[epoch 22] train_loss: 1.273  val_accuracy: 0.530\n",
      "train epoch[23/40] loss:1.385: 100%|██████████| 348/348 [00:03<00:00, 101.13it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "[epoch 23] train_loss: 1.266  val_accuracy: 0.533\n",
      "train epoch[24/40] loss:1.372: 100%|██████████| 348/348 [00:03<00:00, 102.00it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "[epoch 24] train_loss: 1.260  val_accuracy: 0.535\n",
      "train epoch[25/40] loss:1.359: 100%|██████████| 348/348 [00:03<00:00, 103.22it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "[epoch 25] train_loss: 1.253  val_accuracy: 0.539\n",
      "train epoch[26/40] loss:1.346: 100%|██████████| 348/348 [00:03<00:00, 103.36it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "[epoch 26] train_loss: 1.247  val_accuracy: 0.541\n",
      "train epoch[27/40] loss:1.333: 100%|██████████| 348/348 [00:03<00:00, 99.09it/s] \n",
      "100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "[epoch 27] train_loss: 1.241  val_accuracy: 0.542\n",
      "train epoch[28/40] loss:1.319: 100%|██████████| 348/348 [00:03<00:00, 92.19it/s] \n",
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "[epoch 28] train_loss: 1.236  val_accuracy: 0.544\n",
      "train epoch[29/40] loss:1.304: 100%|██████████| 348/348 [00:03<00:00, 99.44it/s] \n",
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "[epoch 29] train_loss: 1.230  val_accuracy: 0.549\n",
      "train epoch[30/40] loss:1.289: 100%|██████████| 348/348 [00:03<00:00, 100.50it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "[epoch 30] train_loss: 1.225  val_accuracy: 0.550\n",
      "train epoch[31/40] loss:1.273: 100%|██████████| 348/348 [00:03<00:00, 100.86it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "[epoch 31] train_loss: 1.220  val_accuracy: 0.553\n",
      "train epoch[32/40] loss:1.259: 100%|██████████| 348/348 [00:03<00:00, 103.02it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "[epoch 32] train_loss: 1.215  val_accuracy: 0.553\n",
      "train epoch[33/40] loss:1.245: 100%|██████████| 348/348 [00:03<00:00, 100.06it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "[epoch 33] train_loss: 1.210  val_accuracy: 0.555\n",
      "train epoch[34/40] loss:1.231: 100%|██████████| 348/348 [00:03<00:00, 100.90it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "[epoch 34] train_loss: 1.205  val_accuracy: 0.557\n",
      "train epoch[35/40] loss:1.219: 100%|██████████| 348/348 [00:03<00:00, 102.98it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "[epoch 35] train_loss: 1.201  val_accuracy: 0.559\n",
      "train epoch[36/40] loss:1.208: 100%|██████████| 348/348 [00:03<00:00, 101.18it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "[epoch 36] train_loss: 1.197  val_accuracy: 0.561\n",
      "train epoch[37/40] loss:1.197: 100%|██████████| 348/348 [00:03<00:00, 97.26it/s] \n",
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "[epoch 37] train_loss: 1.193  val_accuracy: 0.562\n",
      "train epoch[38/40] loss:1.184: 100%|██████████| 348/348 [00:03<00:00, 97.05it/s] \n",
      "100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "[epoch 38] train_loss: 1.189  val_accuracy: 0.562\n",
      "train epoch[39/40] loss:1.174: 100%|██████████| 348/348 [00:03<00:00, 102.68it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "[epoch 39] train_loss: 1.185  val_accuracy: 0.562\n",
      "train epoch[40/40] loss:1.165: 100%|██████████| 348/348 [00:03<00:00, 98.80it/s] \n",
      "100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "[epoch 40] train_loss: 1.181  val_accuracy: 0.564\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "for epoch in range(epochs):\n",
    "        # train\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_bar = tqdm(trainloader, file=sys.stdout)\n",
    "        for step, data in enumerate(train_bar):\n",
    "            images, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images.to(device))\n",
    "            loss = loss_fn(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
    "                                                                     epochs,\n",
    "                                                                     loss)\n",
    "\n",
    "        # validate\n",
    "        model.eval()\n",
    "        acc = 0.0  # accumulate accurate number / epoch\n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(testloader, file=sys.stdout) # show progress\n",
    "            for val_data in val_bar:\n",
    "                val_images, val_labels = val_data\n",
    "                outputs = model(val_images.to(device))\n",
    "                predict_y = torch.max(outputs, dim=1)[1]\n",
    "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "\n",
    "        val_accurate = acc / test_num\n",
    "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
    "              (epoch + 1, running_loss / train_steps, val_accurate))\n",
    "\n",
    "        if val_accurate > best_acc:\n",
    "            best_acc = val_accurate\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): Tanh()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): Tanh()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=400, out_features=120, bias=True)\n",
       "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (3): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index = 5\n",
    "\n",
    "test_lab = test_label[test_index]\n",
    "test_img = val_images[test_index].unsqueeze(0)\n",
    "\n",
    "weights_path = \"./LeNet.pth\"\n",
    "assert os.path.exists(weights_path), \"file: '{}' dose not exist.\".format(weights_path)\n",
    "model.load_state_dict(torch.load(weights_path))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6], device='cuda:0')\n",
      "tensor(6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(test_img.to(device))\n",
    "    predict_y = torch.max(outputs, dim=1)[1]\n",
    "    print(predict_y)\n",
    "    print(test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ryan': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e70b0d8493b7f59e214a43b868537ebeafe12cb89daa279090c57b89e62c1c99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
